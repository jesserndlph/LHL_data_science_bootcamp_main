{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines and Model Persistence - W07D1\n",
    "### Instructor: Eric Elmoznino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview - Pipelines\n",
    "- Motivation and example\n",
    "- Feature unions\n",
    "- Column transformers\n",
    "- Visualizing pipelines\n",
    "- Hyperparameter tuning with pipelines\n",
    "- Custom class in a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Motivation and example\n",
    "Consider the following example of a diabetes vs. non-diabetes classification task in Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6948051948051948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns='class')\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several inconvenient things about this:\n",
    "1. We have a lot of ugly code. We keep calling `.fit()` and `.transform()` on different objects, and\n",
    "we keep having to rename transformed variables so as not to cause confusions later in our notebook.\n",
    "2. Our preprocessing and modeling code is distributed and therefore error-prone. If we try running our model \n",
    "somewhere else and forget to copy over a step (e.g. we don't apply StandardScaler to the test set), \n",
    "then our model will not work as expected.\n",
    "3. We can only use convenient Sklearn functions/classes such as `GridSearchCV()` on the *model class* (e.g. LogisticRegression). What if we want to try different numbers of components, or different scaling methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The solution: Sklearn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6948051948051948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "                           ('pca', PCA(n_components=3)),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much cleaner this code is. The composite model created using `Pipeline`\n",
    "can be used just like any other Sklearn model you have learned, which means that it\n",
    "can also be passed to functions like `cross_val_score()`.\n",
    "\n",
    "To get a better understanding of what is happening under the hood,\n",
    "let's try to build our own pipeline-like class that has some of the\n",
    "same core functionality as the Sklearn one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicPipeline:\n",
    "    \n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        print('Called .fit()')\n",
    "        # Fit all preprocessing modules and sequentially transform input using them\n",
    "        for name, estimator in self.steps[:-1]:\n",
    "            print(f'Fitting {name}')\n",
    "            estimator.fit(X)\n",
    "            print(f'Transforming with {name}')\n",
    "            X = estimator.transform(X)\n",
    "        \n",
    "        # Fit the final (prediction) module\n",
    "        name, estimator = self.steps[-1]\n",
    "        print(f'Fitting {name}\\n')\n",
    "        estimator.fit(X, y)\n",
    "        \n",
    "        # Return fitted self so that we can write things like \"model = model.fit(X, y)\",\n",
    "        # in addition to just \"model.fit(X, y)\" on its own line\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        print('Called .predict()')\n",
    "        # Sequentially transform input using all the preprocessing modules\n",
    "        for name, estimator in self.steps[:-1]:\n",
    "            print(f'Transforming with {name}')\n",
    "            X = estimator.transform(X)\n",
    "        \n",
    "        # Predict using the final module\n",
    "        name, estimator = self.steps[-1]\n",
    "        print(f'Predicting with {name}\\n')\n",
    "        y_pred = estimator.predict(X)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called .fit()\n",
      "Fitting scaling\n",
      "Transforming with scaling\n",
      "Fitting pca\n",
      "Transforming with pca\n",
      "Fitting classifier\n",
      "\n",
      "Called .predict()\n",
      "Transforming with scaling\n",
      "Transforming with pca\n",
      "Predicting with classifier\n",
      "\n",
      "Test set accuracy: 0.6948051948051948\n"
     ]
    }
   ],
   "source": [
    "pipeline = BasicPipeline(steps=[('scaling', StandardScaler()),\n",
    "                                ('pca', PCA(n_components=3)),\n",
    "                                ('classifier', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature unions\n",
    "`Pipeline` lets us specify a sequence of steps that will be executed in one after the other (i.e. in `series`),\n",
    "but want if we want branches in our process? For instance, what if we want to create two different sets\n",
    "of features and use both of them when fitting our model?\n",
    "\n",
    "For this type of application, we can use a `FeatureUnion`. It is an Sklearn class that lets us join the\n",
    "outputs of several steps through *concatenation* (i.e. in parallel). `FeatureUnion`'s can be composed with `Pipeline`'s however much we want.\n",
    "\n",
    "![](images/series_and_parallel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.7337662337662337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "feature_union = FeatureUnion([('pca', PCA(n_components=3)), \n",
    "                              ('select_best', SelectKBest(k=6))])\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "                           ('features', feature_union),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Column transformers\n",
    "Often times, our preprocessing and feature engineering is specific to columns in a\n",
    "`DataFrame`. For instance, for a dataset with both numerical and categorical features,\n",
    "we may want to do something like the following:\n",
    "1. For *numeric* columns:\n",
    "    1. Impute missing values with the *mean*\n",
    "    2. Standard scale the values\n",
    "2. For *categorical* columns:\n",
    "    1. Impute missing values with the *mode*\n",
    "    2. One-hot-encode the categories\n",
    "3. Fit a model to the resulting features\n",
    "\n",
    "Luckily, there is a straightforward way to perform steps 1 and 2\n",
    "in a larger pipeline using the `ColumnTransformer`. Initializing a `ColumnTransformer`\n",
    "has a very similar syntax to that of a `FeatureUnion` or `Pipeline`, except that\n",
    "we must also specify the *column names* that each transform applies to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seaborn import load_dataset\n",
    "\n",
    "tips_df = load_dataset('tips')\n",
    "X_tips, y_tips = tips_df.drop(columns='tip'), tips_df['tip'].values\n",
    "X_train_tips, X_test_tips, y_train_tips, y_test_tips = train_test_split(X_tips, y_tips, random_state=27)\n",
    "\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set r^2: 0.3492266984179321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "numeric_transform = Pipeline([('impute_mean', SimpleImputer(strategy='mean')), \n",
    "                              ('scaling', StandardScaler())])\n",
    "categorical_transform = Pipeline([('impute_mode', SimpleImputer(strategy='most_frequent')), \n",
    "                                  ('one-hot-encode', OneHotEncoder(sparse=False))])\n",
    "\n",
    "preprocessing_tips = ColumnTransformer([('numeric', numeric_transform, ['total_bill', 'size']), \n",
    "                                        ('categorical', categorical_transform, ['sex', 'smoker', 'day', 'time'])])\n",
    "\n",
    "pipeline_tips = Pipeline([('preprocessing', preprocessing_tips), \n",
    "                          ('model', LinearRegression())])\n",
    "pipeline_tips.fit(X_train_tips, y_train_tips)\n",
    "\n",
    "r2 = pipeline_tips.score(X_test_tips, y_test_tips)\n",
    "print(f'Test set r^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the `ColumnTransformer` actually doing? We can get a better sense by looking at our data before and after\n",
    "the transform it applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill     sex smoker  day    time  size\n",
       "0       16.99  Female     No  Sun  Dinner     2\n",
       "1       10.34    Male     No  Sun  Dinner     3\n",
       "2       21.01    Male     No  Sun  Dinner     3\n",
       "3       23.68    Male     No  Sun  Dinner     2\n",
       "4       24.59  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial data\n",
    "X_tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessed data\n",
    "X_tips_preprocessed = preprocessing_tips.fit_transform(X_tips)\n",
    "X_tips_preprocessed[:5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizing pipelines\n",
    "Another advantage of having these pipelines is that we can quickly visualize complex workflows used in our\n",
    "modeling as HTML, which can be helpful for debugging purposes or presentations.\n",
    "\n",
    "<sub>*Note: I highly recommend you use this in your own presentations as a substitute for (or in addition to) code.*</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-9dd66f69-c098-461c-83d7-1065921777d1 {color: black;background-color: white;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 pre{padding: 0;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-toggleable {background-color: white;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-item {z-index: 1;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-parallel-item:only-child::after {width: 0;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-9dd66f69-c098-461c-83d7-1065921777d1 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-9dd66f69-c098-461c-83d7-1065921777d1\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"316567d6-4eb8-432b-9010-32f42726f07f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"316567d6-4eb8-432b-9010-32f42726f07f\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                ('features',\n",
       "                 FeatureUnion(transformer_list=[('pca', PCA(n_components=3)),\n",
       "                                                ('select_best',\n",
       "                                                 SelectKBest(k=6))])),\n",
       "                ('classifier', LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e7c649e5-a115-4b03-9bb0-98b99f0309b1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e7c649e5-a115-4b03-9bb0-98b99f0309b1\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"14919110-78c9-4f60-86eb-e5fc5cec391b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"14919110-78c9-4f60-86eb-e5fc5cec391b\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[('pca', PCA(n_components=3)),\n",
       "                               ('select_best', SelectKBest(k=6))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>pca</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"aed2bf1a-895a-424e-8a54-db05f5cd53b2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"aed2bf1a-895a-424e-8a54-db05f5cd53b2\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=3)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>select_best</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f44b3a0c-d66d-4feb-8ccb-55d89897e38f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f44b3a0c-d66d-4feb-8ccb-55d89897e38f\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=6)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b94116fd-5047-49c5-a14d-16cab6b210dc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b94116fd-5047-49c5-a14d-16cab6b210dc\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                ('features',\n",
       "                 FeatureUnion(transformer_list=[('pca', PCA(n_components=3)),\n",
       "                                                ('select_best',\n",
       "                                                 SelectKBest(k=6))])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display HTML representation in a jupyter context\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also click on the individual parts in the diagram (e.g. PCA) to see their arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, save the HTML to a file\n",
    "from sklearn.utils import estimator_html_repr\n",
    "\n",
    "with open('images/model_pipeline.html', 'w') as f:  \n",
    "    f.write(estimator_html_repr(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hyperparameter tuning with pipelines\n",
    "Normally, if we want to tune hyperparameters using something like `GridSearchCV`, we need to pass it:\n",
    "1. A model object.\n",
    "2. A dictionary of (parameter name, list of values to try) pairs.\n",
    "\n",
    "When not using pipelines, we can only tune hyperparameters for a single model (the one we specify as the\n",
    "model in `GridSearchCV`. As we've seen, however, we can create composite models using `Pipeline`. We can\n",
    "then pass this composite model to `GridSearchCV` and tune hyperparameters for multiple components at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27     0\n",
       "24     1\n",
       "436    0\n",
       "284    1\n",
       "242    1\n",
       "      ..\n",
       "508    0\n",
       "12     0\n",
       "627    0\n",
       "690    0\n",
       "578    0\n",
       "Name: class, Length: 614, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test set accuracy: 0.7467532467532467\n",
      "Achieved with hyperparameters: {'classifier__alpha': 0.001, 'features__pca__n_components': 3, 'features__select_best__k': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "feature_union = FeatureUnion([('pca', PCA()), \n",
    "                              ('select_best', SelectKBest())])\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "                           ('features', feature_union),\n",
    "                           ('classifier', RidgeClassifier())])\n",
    "\n",
    "# Find the best hyperparameters using GridSearchCV on the train set\n",
    "param_grid = {'classifier__alpha': [0.001, 0.01, 0.1], \n",
    "              'features__pca__n_components': [3, 5],\n",
    "              'features__select_best__k': [1, 3, 6]}\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_hyperparams = grid.best_params_\n",
    "best_acc = grid.score(X_test, y_test)\n",
    "print(f'Best test set accuracy: {best_acc}\\nAchieved with hyperparameters: {best_hyperparams}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to trying out different hyperparameters for a given step in the pipeline, you can also try different classes altogether. For instance, what if we wanted to try both Logistic Regression and SVM for the \"classifier\" step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test set accuracy: 0.7337662337662337\n",
      "Achieved with hyperparameters: {'classifier': LogisticRegression(), 'features__pca__n_components': 5, 'features__select_best__k': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "                           ('features', feature_union),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "\n",
    "# Find the best hyperparameters and model using GridSearchCV on the train set\n",
    "param_grid = {'classifier': [LogisticRegression(), SVC()],    # Which is better, Logistic Regression or an SVM Classifier?\n",
    "              'features__pca__n_components': [3, 5],\n",
    "              'features__select_best__k': [1, 3, 6]}\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_hyperparams = grid.best_params_\n",
    "best_acc = grid.score(X_test, y_test)\n",
    "print(f'Best test set accuracy: {best_acc}\\nAchieved with hyperparameters: {best_hyperparams}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Custom class in a pipeline\n",
    "In some scenarios, the standard Sklearn models and preprocessing functions may not be enough, and you will\n",
    "have to generate your own custom classes.\n",
    "However, you'll still want the convenience of `Pipeline` and the advantages that come with it.\n",
    "\n",
    "Here, we'll see how to embed your own custom class into an Sklearn `Pipeline`. We'll be using a dummy dataset where $y = 5x_1 + 2\\sqrt{x_2}$. A linear regression model cannot find the appropriate solution, but a linear regression model that takes the square roots of the features (in addition to the features themselves) can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(1000, 2) * 10\n",
    "y = 5 * X[:, 0] + 2 * np.sqrt(X[:, 1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:600], X[600:], y[:600], y[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 0.32754405194167885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.99661208, 0.50410481])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'Test set RMSE: {rmse}')\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance just using linear regression isn't perfect. Let's create a custom transformer\n",
    "that generates a square-rooted version of the features, and use it in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class RootTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, root):\n",
    "        # Your __init__ function takes in arguments as input\n",
    "        # and does some initialization, such as creating model parameters.\n",
    "        print('init() called')\n",
    "        self.root = root\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        # Your forward() function takes in an X (and optionally a y)\n",
    "        # and fits its parameters to the data. It then returns \"self\".\n",
    "        # This transformer does not fit anything, because it is parameterless.\n",
    "        print('fit() called')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        # Your transform() function takes in an X (and optionally a y)\n",
    "        # and spits out the transformed output.\n",
    "        # This transformer returns the original features and their nth root.\n",
    "        print('transform() called')\n",
    "        X_root = X ** (1 / self.root)\n",
    "        X = np.concatenate((X, X_root), axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init() called\n",
      "fit() called\n",
      "transform() called\n",
      "transform() called\n",
      "\n",
      "Test set RMSE: 1.8381122774185994e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.00000000e+00,  1.73472348e-17, -1.21430643e-16,  2.00000000e+00])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[('root', RootTransformer(root=2)), \n",
    "                           ('regression', LinearRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'\\nTest set RMSE: {rmse}')\n",
    "pipeline.steps[1][1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if the class you're trying to implement really only has a `.transform()` component (i.e. `__init__()` and `fit()` are empty), you can use the `FunctionTransformer()` from the `sklearn.preprocessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def sqrt_transform(X):\n",
    "    X_sqrt = X ** (1 / 2)\n",
    "    X = np.concatenate((X, X_sqrt), axis=1)\n",
    "    return X\n",
    "\n",
    "sqrt_transform_object = FunctionTransformer(sqrt_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 1.8381122774185994e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.00000000e+00,  1.73472348e-17, -1.21430643e-16,  2.00000000e+00])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[('root', sqrt_transform_object), \n",
    "                           ('regression', LinearRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'Test set RMSE: {rmse}')\n",
    "pipeline.steps[1][1].coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
