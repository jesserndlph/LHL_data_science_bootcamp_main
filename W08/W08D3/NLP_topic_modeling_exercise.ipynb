{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Topic Modeling Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:12.932082Z",
     "start_time": "2020-04-29T12:18:12.200358Z"
    }
   },
   "outputs": [],
   "source": [
    "# import TfidfVectorizer and CountVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# import fetch_20newsgroups from sklearn.datasets\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# import NMF and LatentDirichletAllocation from sklearn\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:14.463840Z",
     "start_time": "2020-04-29T12:18:13.020189Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a variable called `'no_features'` and set its value to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:15.590700Z",
     "start_time": "2020-04-29T12:18:15.585820Z"
    }
   },
   "outputs": [],
   "source": [
    "no_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a variable `'no_topics'` and set its value to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:16.743304Z",
     "start_time": "2020-04-29T12:18:16.737763Z"
    }
   },
   "outputs": [],
   "source": [
    "no_topics = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate a TfidfVectorizer with the following parameters:\n",
    "\n",
    "\n",
    "    * max_df = 0.95\n",
    "    * min_df = 2\n",
    "    * max_features = no_features\n",
    "    * stop_words = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:17.892838Z",
     "start_time": "2020-04-29T12:18:17.888668Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(max_df=0.95, \n",
    "                         min_df=2,\n",
    "                         max_features=no_features,\n",
    "                         stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use fit_transform method of TfidfVectorizer to transform the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:21.486038Z",
     "start_time": "2020-04-29T12:18:19.135830Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_fit = tf_idf.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get the features names from TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:22.661253Z",
     "start_time": "2020-04-29T12:18:22.656169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '12',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '20',\n",
       " '25',\n",
       " 'a86',\n",
       " 'available',\n",
       " 'ax',\n",
       " 'b8f',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bit',\n",
       " 'case',\n",
       " 'com',\n",
       " 'come',\n",
       " 'course',\n",
       " 'data',\n",
       " 'day',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'don',\n",
       " 'drive',\n",
       " 'edu',\n",
       " 'fact',\n",
       " 'far',\n",
       " 'file',\n",
       " 'g9v',\n",
       " 'god',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'government',\n",
       " 'help',\n",
       " 'information',\n",
       " 'jesus',\n",
       " 'just',\n",
       " 'key',\n",
       " 'know',\n",
       " 'law',\n",
       " 'let',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'little',\n",
       " 'll',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'max',\n",
       " 'mr',\n",
       " 'need',\n",
       " 'new',\n",
       " 'number',\n",
       " 'people',\n",
       " 'point',\n",
       " 'power',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'program',\n",
       " 'question',\n",
       " 'read',\n",
       " 'really',\n",
       " 'right',\n",
       " 'run',\n",
       " 'said',\n",
       " 'say',\n",
       " 'second',\n",
       " 'set',\n",
       " 'software',\n",
       " 'space',\n",
       " 'state',\n",
       " 'sure',\n",
       " 'tell',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'time',\n",
       " 'true',\n",
       " 'try',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 've',\n",
       " 'want',\n",
       " 'way',\n",
       " 'windows',\n",
       " 'work',\n",
       " 'world',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate NMF and fit transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:24.532755Z",
     "start_time": "2020-04-29T12:18:23.661009Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tf_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA w/ Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate a CountVectorizer with following parameters:\n",
    "\n",
    "\n",
    "    * max_df = 0.95\n",
    "    * min_df = 2\n",
    "    * max_features = no_features\n",
    "    * stop_words = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:25.547906Z",
     "start_time": "2020-04-29T12:18:25.540452Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use fit_transform method of CountVectorizer to transform documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:29.307223Z",
     "start_time": "2020-04-29T12:18:26.637153Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_fit = cv.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get the features names from TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:31.516381Z",
     "start_time": "2020-04-29T12:18:31.498740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '12',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '20',\n",
       " '25',\n",
       " 'a86',\n",
       " 'available',\n",
       " 'ax',\n",
       " 'b8f',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bit',\n",
       " 'case',\n",
       " 'com',\n",
       " 'come',\n",
       " 'course',\n",
       " 'data',\n",
       " 'day',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'don',\n",
       " 'drive',\n",
       " 'edu',\n",
       " 'fact',\n",
       " 'far',\n",
       " 'file',\n",
       " 'g9v',\n",
       " 'god',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'government',\n",
       " 'help',\n",
       " 'information',\n",
       " 'jesus',\n",
       " 'just',\n",
       " 'key',\n",
       " 'know',\n",
       " 'law',\n",
       " 'let',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'little',\n",
       " 'll',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'max',\n",
       " 'mr',\n",
       " 'need',\n",
       " 'new',\n",
       " 'number',\n",
       " 'people',\n",
       " 'point',\n",
       " 'power',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'program',\n",
       " 'question',\n",
       " 'read',\n",
       " 'really',\n",
       " 'right',\n",
       " 'run',\n",
       " 'said',\n",
       " 'say',\n",
       " 'second',\n",
       " 'set',\n",
       " 'software',\n",
       " 'space',\n",
       " 'state',\n",
       " 'sure',\n",
       " 'tell',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'time',\n",
       " 'true',\n",
       " 'try',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 've',\n",
       " 'want',\n",
       " 'way',\n",
       " 'windows',\n",
       " 'work',\n",
       " 'world',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate LatentDirichletAllocation and fit transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:03.315322Z",
     "start_time": "2020-04-29T12:18:32.768365Z"
    }
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(cv_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a function `display_topics` that is able to display the top words in a topic for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:04.476192Z",
     "start_time": "2020-04-29T12:19:04.469045Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* display top 10 words from each topic from NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:05.672461Z",
     "start_time": "2020-04-29T12:19:05.656545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "did didn make time like know people just say said\n",
      "Topic 1:\n",
      "thanks mail know help does god doesn don drive edu\n",
      "Topic 2:\n",
      "does know like use thanks work make say just way\n",
      "Topic 3:\n",
      "edu mail new got don drive fact far file g9v\n",
      "Topic 4:\n",
      "know don does like thanks let need just want help\n",
      "Topic 5:\n",
      "like just don know use make people does think new\n",
      "Topic 6:\n",
      "just like don think way good ve say people right\n",
      "Topic 7:\n",
      "use used like using does need work just way want\n",
      "Topic 8:\n",
      "people think don just like make say government know time\n",
      "Topic 9:\n",
      "good just like think don really time make better thing\n",
      "Topic 10:\n",
      "think don people just good like really say way time\n",
      "Topic 11:\n",
      "god jesus believe say people does things fact said think\n",
      "Topic 12:\n",
      "time long like just years good don think know did\n",
      "Topic 13:\n",
      "windows using file thanks use program run problem software help\n",
      "Topic 14:\n",
      "drive thanks problem work years god doesn don edu fact\n",
      "Topic 15:\n",
      "problem using help know time just work god doesn don\n",
      "Topic 16:\n",
      "don know think just like people want say make good\n",
      "Topic 17:\n",
      "ve got just know good like don think time use\n",
      "Topic 18:\n",
      "years good doesn don drive edu fact far file g9v\n",
      "Topic 19:\n",
      "com years good don drive edu fact far file g9v\n",
      "Topic 20:\n",
      "need want help know use thanks years god doesn don\n",
      "Topic 21:\n",
      "used use using years going does doesn don drive edu\n",
      "Topic 22:\n",
      "year years good better think time make new ll help\n",
      "Topic 23:\n",
      "right just way people like don make let information file\n",
      "Topic 24:\n",
      "make like don just does sure people want way use\n",
      "Topic 25:\n",
      "look like good doesn don drive edu fact far file\n",
      "Topic 26:\n",
      "mail thanks edu years going doesn don drive fact far\n",
      "Topic 27:\n",
      "way just think don like use make right people point\n",
      "Topic 28:\n",
      "want don know just need good years god doesn drive\n",
      "Topic 29:\n",
      "10 12 15 20 14 25 16 new years fact\n",
      "Topic 30:\n",
      "new like time years used just make god doesn don\n",
      "Topic 31:\n",
      "really like think don just good doesn drive edu fact\n",
      "Topic 32:\n",
      "said time people did say fact think like going just\n",
      "Topic 33:\n",
      "say just don like people does think did time way\n",
      "Topic 34:\n",
      "space program years different doesn don drive edu fact far\n",
      "Topic 35:\n",
      "tell years going doesn don drive edu fact far file\n",
      "Topic 36:\n",
      "work just does use don going doesn drive edu fact\n",
      "Topic 37:\n",
      "file windows use program years going doesn don drive edu\n",
      "Topic 38:\n",
      "believe don god people think point does drive edu fact\n",
      "Topic 39:\n",
      "got ve just going doesn don drive edu fact far\n",
      "Topic 40:\n",
      "using use problem windows years going doesn don drive edu\n",
      "Topic 41:\n",
      "sure make years going doesn don drive edu fact far\n",
      "Topic 42:\n",
      "question years going doesn don drive edu fact far file\n",
      "Topic 43:\n",
      "probably years going doesn don drive edu fact far file\n",
      "Topic 44:\n",
      "ll let just like going doesn don drive edu fact\n",
      "Topic 45:\n",
      "key use using used bit like information number data way\n",
      "Topic 46:\n",
      "going just time know like think don key god doesn\n",
      "Topic 47:\n",
      "years time year new 14 don drive edu fact far\n",
      "Topic 48:\n",
      "program using use know help time windows run drive fact\n",
      "Topic 49:\n",
      "help thanks need know does god doesn don drive edu\n",
      "Topic 50:\n",
      "true good doesn don drive edu fact far file g9v\n",
      "Topic 51:\n",
      "point people years going don drive edu fact far file\n",
      "Topic 52:\n",
      "better think good don just years doesn drive edu fact\n",
      "Topic 53:\n",
      "case years good don drive edu fact far file g9v\n",
      "Topic 54:\n",
      "software use years going doesn don drive edu fact far\n",
      "Topic 55:\n",
      "information thanks available years going doesn don drive edu fact\n",
      "Topic 56:\n",
      "best years good don drive edu fact far file g9v\n",
      "Topic 57:\n",
      "number good doesn don drive edu fact far file g9v\n",
      "Topic 58:\n",
      "read years going doesn don drive edu fact far file\n",
      "Topic 59:\n",
      "doesn like just years going don drive edu fact far\n",
      "Topic 60:\n",
      "didn did time know law god let doesn don drive\n",
      "Topic 61:\n",
      "power years going doesn don drive edu fact far file\n",
      "Topic 62:\n",
      "list good doesn don drive edu fact far file g9v\n",
      "Topic 63:\n",
      "data use years going doesn don drive edu fact far\n",
      "Topic 64:\n",
      "law government state fact right people years doesn don drive\n",
      "Topic 65:\n",
      "let know years going doesn don drive edu fact far\n",
      "Topic 66:\n",
      "world people years going doesn don drive edu fact far\n",
      "Topic 67:\n",
      "government people state law fact right make years just help\n",
      "Topic 68:\n",
      "lot like good doesn don drive edu fact far file\n",
      "Topic 69:\n",
      "00 10 20 got don drive edu fact far file\n",
      "Topic 70:\n",
      "long time good doesn don drive edu fact far file\n",
      "Topic 71:\n",
      "try years good doesn don drive edu fact far file\n",
      "Topic 72:\n",
      "course years good don drive edu fact far file g9v\n",
      "Topic 73:\n",
      "things like people don different doesn drive edu fact far\n",
      "Topic 74:\n",
      "available use using years good doesn don drive edu fact\n",
      "Topic 75:\n",
      "set years going doesn don drive edu fact far file\n",
      "Topic 76:\n",
      "day years good don drive edu fact far file g9v\n",
      "Topic 77:\n",
      "thing like good law know doesn don drive edu fact\n",
      "Topic 78:\n",
      "line good doesn don drive edu fact far file g9v\n",
      "Topic 79:\n",
      "run years going doesn don drive edu fact far file\n",
      "Topic 80:\n",
      "little just good doesn don drive edu fact far file\n",
      "Topic 81:\n",
      "state law years going doesn don drive edu fact far\n",
      "Topic 82:\n",
      "second time different doesn don drive edu fact far file\n",
      "Topic 83:\n",
      "fact years good doesn don drive edu far file g9v\n",
      "Topic 84:\n",
      "different good doesn don drive edu fact far file g9v\n",
      "Topic 85:\n",
      "come years good don drive edu fact far file g9v\n",
      "Topic 86:\n",
      "far years good doesn don drive edu fact file g9v\n",
      "Topic 87:\n",
      "jesus god say believe people point did come don drive\n",
      "Topic 88:\n",
      "bit 16 years good don drive edu fact far file\n",
      "Topic 89:\n",
      "mr years good doesn don drive edu fact far file\n",
      "Topic 90:\n",
      "20 10 15 25 years got drive edu fact far\n",
      "Topic 91:\n",
      "15 10 14 20 16 25 file good going god\n",
      "Topic 92:\n",
      "16 15 12 14 25 20 file good going god\n",
      "Topic 93:\n",
      "25 20 years got don drive edu fact far file\n",
      "Topic 94:\n",
      "12 10 14 16 25 15 file good going god\n",
      "Topic 95:\n",
      "max years good doesn don drive edu fact far file\n",
      "Topic 96:\n",
      "ax max g9v b8f years good don drive edu fact\n",
      "Topic 97:\n",
      "b8f a86 g9v years got don drive edu fact far\n",
      "Topic 98:\n",
      "14 15 12 10 a86 16 years g9v good going\n",
      "Topic 99:\n",
      "years good doesn don drive edu fact far file g9v\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf, tf_idf.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* display top 10 words from each topic from LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:06.842806Z",
     "start_time": "2020-04-29T12:19:06.831721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "point state right need long second fact does people things\n",
      "Topic 1:\n",
      "day tell like going just read problem need think know\n",
      "Topic 2:\n",
      "sure point want good help did government say use question\n",
      "Topic 3:\n",
      "think need best 00 a86 tell want using new people\n",
      "Topic 4:\n",
      "ax max b8f g9v a86 14 mr ll 25 probably\n",
      "Topic 5:\n",
      "god true say jesus believe things people does did know\n",
      "Topic 6:\n",
      "said second years tell work new right ll true like\n",
      "Topic 7:\n",
      "probably look like tell need used point want long run\n",
      "Topic 8:\n",
      "available software run like new need people used probably work\n",
      "Topic 9:\n",
      "mail list like new time tell does different use 15\n",
      "Topic 10:\n",
      "think 16 program point com space case let probably use\n",
      "Topic 11:\n",
      "help set use like does tell things work used new\n",
      "Topic 12:\n",
      "com know g9v way mr let look don point try\n",
      "Topic 13:\n",
      "don like know just think say ll tell need try\n",
      "Topic 14:\n",
      "time years long like far just work make better people\n",
      "Topic 15:\n",
      "good like tell just day think probably lot believe right\n",
      "Topic 16:\n",
      "just right like use don true make doesn did got\n",
      "Topic 17:\n",
      "government come set help state bit jesus sure point little\n",
      "Topic 18:\n",
      "edu mail com file available software line data use list\n",
      "Topic 19:\n",
      "make case like does look good don point thanks state\n",
      "Topic 20:\n",
      "long file run does look 20 bit program course 14\n",
      "Topic 21:\n",
      "00 new 20 15 10 list 25 thing help day\n",
      "Topic 22:\n",
      "law fact right government state people new just used come\n",
      "Topic 23:\n",
      "case probably space run doesn point sure little year want\n",
      "Topic 24:\n",
      "second used fact b8f point really 12 things data 25\n",
      "Topic 25:\n",
      "program run use need time look like new world used\n",
      "Topic 26:\n",
      "got data line jesus thanks right need problem long far\n",
      "Topic 27:\n",
      "try space set max mr said file right 00 far\n",
      "Topic 28:\n",
      "think mr just like going ll does time ve use\n",
      "Topic 29:\n",
      "read try work need long help right true time does\n",
      "Topic 30:\n",
      "ve better run like need got long does tell just\n",
      "Topic 31:\n",
      "data second use run years need 16 new long time\n",
      "Topic 32:\n",
      "used believe power ll going did b8f need program good\n",
      "Topic 33:\n",
      "used work information want world lot 12 doesn year windows\n",
      "Topic 34:\n",
      "doesn government really people need com bit believe set tell\n",
      "Topic 35:\n",
      "available case sure things second want com time thing 25\n",
      "Topic 36:\n",
      "best need does like use right far power time new\n",
      "Topic 37:\n",
      "know does like need help don thanks doesn just mail\n",
      "Topic 38:\n",
      "drive use need new time does got going better run\n",
      "Topic 39:\n",
      "doesn help didn say don make said better need file\n",
      "Topic 40:\n",
      "believe far things new question doesn true got god second\n",
      "Topic 41:\n",
      "want better try work things does time just 14 program\n",
      "Topic 42:\n",
      "information work does new don available know government thing years\n",
      "Topic 43:\n",
      "course tell need just new ve don year good think\n",
      "Topic 44:\n",
      "new ll like need time just tell going got used\n",
      "Topic 45:\n",
      "bit like think don need just really way know different\n",
      "Topic 46:\n",
      "way make work true long tell better think good got\n",
      "Topic 47:\n",
      "list thing space bit max set tell years didn going\n",
      "Topic 48:\n",
      "problem try run tell help work long new edu using\n",
      "Topic 49:\n",
      "going sure make work right things like long just know\n",
      "Topic 50:\n",
      "00 using say ll ax let file number law far\n",
      "Topic 51:\n",
      "day mail max think say problem ll using thanks set\n",
      "Topic 52:\n",
      "10 12 14 20 25 like second 15 new list\n",
      "Topic 53:\n",
      "got didn like just tell long things going used know\n",
      "Topic 54:\n",
      "doesn try day true want way thanks good long ve\n",
      "Topic 55:\n",
      "going com best power time make 12 space law things\n",
      "Topic 56:\n",
      "question true like think look work know want need case\n",
      "Topic 57:\n",
      "information know got b8f drive 00 things use years little\n",
      "Topic 58:\n",
      "windows power like run need tell just help 14 using\n",
      "Topic 59:\n",
      "using use work run like need does just time don\n",
      "Topic 60:\n",
      "let 25 way drive world said want don state course\n",
      "Topic 61:\n",
      "g9v a86 state come way b8f don second year right\n",
      "Topic 62:\n",
      "better ve like does problem different time things got just\n",
      "Topic 63:\n",
      "let need sure don time doesn day really tell right\n",
      "Topic 64:\n",
      "12 did probably power work state use things case let\n",
      "Topic 65:\n",
      "b8f really tell jesus data different world way mail ve\n",
      "Topic 66:\n",
      "25 new like 15 just year way don information best\n",
      "Topic 67:\n",
      "little work like just things tell different bit really know\n",
      "Topic 68:\n",
      "using information 20 space windows ll make time year lot\n",
      "Topic 69:\n",
      "mail good space 25 time way tell really work try\n",
      "Topic 70:\n",
      "bit 10 look drive want 15 didn sure things mail\n",
      "Topic 71:\n",
      "year did years think long just better second case like\n",
      "Topic 72:\n",
      "com like tell need mail 14 true day sure world\n",
      "Topic 73:\n",
      "government time god 00 available set windows thanks far problem\n",
      "Topic 74:\n",
      "set right 20 g9v sure better didn case just 00\n",
      "Topic 75:\n",
      "use used key need like does run true work using\n",
      "Topic 76:\n",
      "25 available government 14 ve just believe mr day run\n",
      "Topic 77:\n",
      "used program far does state doesn available sure using power\n",
      "Topic 78:\n",
      "key lot probably set com drive don sure 10 government\n",
      "Topic 79:\n",
      "really try day run just long say does true tell\n",
      "Topic 80:\n",
      "thanks work need like tell does run help new just\n",
      "Topic 81:\n",
      "doesn lot like just does tell true don problem good\n",
      "Topic 82:\n",
      "mr case 10 used does set didn g9v time program\n",
      "Topic 83:\n",
      "does jesus like say way come think don time things\n",
      "Topic 84:\n",
      "number way ll 12 bit people max government don law\n",
      "Topic 85:\n",
      "edu like need mail new use world state list does\n",
      "Topic 86:\n",
      "available 10 does really ax mr don need 16 far\n",
      "Topic 87:\n",
      "number long like new tell second 20 does years things\n",
      "Topic 88:\n",
      "world come true tell fact way didn time different right\n",
      "Topic 89:\n",
      "people think just like know tell say don need true\n",
      "Topic 90:\n",
      "space program use long work 14 15 years new time\n",
      "Topic 91:\n",
      "government say make like tell does did right years need\n",
      "Topic 92:\n",
      "mr space read program case look going just max let\n",
      "Topic 93:\n",
      "file use run windows available look like new different need\n",
      "Topic 94:\n",
      "15 20 16 14 max 25 12 true 10 new\n",
      "Topic 95:\n",
      "things thing like just say need does know tell true\n",
      "Topic 96:\n",
      "20 doesn try point 14 like does problem did data\n",
      "Topic 97:\n",
      "line run need second doesn say case right good don\n",
      "Topic 98:\n",
      "make lot bit want does com best fact better just\n",
      "Topic 99:\n",
      "different fact did point used tell just time say things\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, cv.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch: Use LDA w/ Gensim to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7257430773ff2786ada9528d4be6e0e9fe11a1482846f09bd681c7e1b20b89d3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
