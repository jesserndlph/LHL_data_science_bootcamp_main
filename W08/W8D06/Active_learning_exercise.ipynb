{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the titanic dataset here: https://drive.google.com/file/d/0Bz9_0VdXvv9bbVhpOEMwUDJ2elU/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will simulate active learning. We will keep the small sample of observations for testing and we will test how quality of the model rises when we use active learning to choose labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Data into variable df\n",
    "import pandas as pd\n",
    "df = pd.read_csv('titanic_dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. fit the first model only on the **start_df** using **SVM** and evaluate accuracy, precision and recall on test_df\n",
    "2. in each iteration, add 10 observations from **df** to your trainset (choose the observation using active learning approach) \n",
    "    - score all observations in df and take 10 where the model isn't sure what class it is. The probability of surviving will be around 50% \n",
    "3. refit the model and evaluate on **test_df** again.    \n",
    "3. the goal is to converge to the optimal solution as fast as possible by choosing **right** observations in each iteration\n",
    "4. plot the graphs for each eval metric, where on the axis x is iteration number, on y is the metric value for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.dropna()\n",
    "# DROP CATEGORICAL VARIABLES\n",
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df, columns=['Sex','Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df2[['Age','Fare']] = scaler.fit_transform(df2[['Age','Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430956</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038948</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass       Age  SibSp  Parch      Fare  Sex_male  \\\n",
       "1             2         1       1  0.468892      1      0  0.139136         0   \n",
       "3             4         1       1  0.430956      1      0  0.103644         0   \n",
       "6             7         0       1  0.671219      0      0  0.101229         1   \n",
       "10           11         1       3  0.038948      1      1  0.032596         0   \n",
       "11           12         1       1  0.721801      0      0  0.051822         0   \n",
       "\n",
       "    Embarked_Q  Embarked_S  \n",
       "1            0           0  \n",
       "3            0           1  \n",
       "6            0           1  \n",
       "10           0           1  \n",
       "11           0           1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SAMPLE\n",
    "# USE THIS SAMPLE ONLY FOR TESTING\n",
    "test_df = df2.sample(n=100, random_state=42)\n",
    "# KEEP ONLY THOSE WHO ARE NOT IN THE TEST SET\n",
    "df = df2[~df2.PassengerId.isin(test_df.PassengerId.tolist())]\n",
    "\n",
    "# FIT THE FIRST MODEL ONLY ON THE DATAFRAME START_DF\n",
    "start_df = df2.sample(n=100, random_state=42)\n",
    "# DROP OBS FROM START_DF FROM DF\n",
    "df = df2[~df2.PassengerId.isin(start_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "svc = SVC(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_df.loc[:, test_df.columns != 'Survived'], test_df.loc[:, 'Survived']\n",
    "start_train, start_test = start_df.loc[:, start_df.columns != 'Survived'], start_df.loc[:, 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 0.875\n",
      "Recall: 0.7903225806451613\n"
     ]
    }
   ],
   "source": [
    "# FIT THE FIRST MODEL\n",
    "svc.fit(start_train, start_test)\n",
    "# PREDICTION\n",
    "y_pred = svc.predict(X_test)\n",
    "# EVALUATION\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1\n",
      " 0 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1]\n",
      "[0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. in each iteration, add 10 observations from **df** to your trainset (choose the observation using active learning approach) \n",
    "    - score all observations in df and take 10 where the model isn't sure what class it is. The probability of surviving will be around 50% \n",
    "3. refit the model and evaluate on **test_df** again.    \n",
    "3. the goal is to converge to the optimal solution as fast as possible by choosing **right** observations in each iteration\n",
    "4. plot the graphs for each eval metric, where on the axis x is iteration number, on y is the metric value for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 10 more samples to the training set\n",
    "# df2 is cleaned training set\n",
    "# test_df is the set to concat to.\n",
    "# let's make functions for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data_and_concat(df2, test_df):\n",
    "    # SAMPLE DATA\n",
    "    sample_df = df2.sample(n=10, random_state=42)\n",
    "    # CONCAT TO THE TEST SET\n",
    "    test_df = pd.concat([test_df, sample_df])\n",
    "    return test_df\n",
    "\n",
    "def split_and_fit(train_df): # use new concatenated training set with +10 samples\n",
    "    start_train, start_test = train_df.loc[:, train_df.columns != 'Survived'], train_df.loc[:, 'Survived']\n",
    "    # FIT THE MODEL\n",
    "    svc.fit(start_train, start_test)\n",
    "    # PREDICTION\n",
    "    y_pred = svc.predict(X_test)\n",
    "    # EVALUATION\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('Precision:', precision_score(y_test, y_pred))\n",
    "    print('Recall:', recall_score(y_test, y_pred))\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this only the first time\n",
    "concat_test_df = sample_data_and_concat(df2, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 10)\n"
     ]
    }
   ],
   "source": [
    "concat_test_df = sample_data_and_concat(df2, concat_test_df) # adds 10 more everytime\n",
    "print(concat_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 0.7741935483870968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_and_fit(concat_test_df) # fit the model with the new concatenated set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Precision: 0.8846153846153846\n",
      "Recall: 0.7419354838709677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell multiple times, see the accuracy increase.\n",
    "concat_test_df = sample_data_and_concat(df2, concat_test_df) # adds 10 more everytime\n",
    "split_and_fit(concat_test_df) # fit the model with the new concatenated set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 10)\n",
      "(83, 10)\n"
     ]
    }
   ],
   "source": [
    "print(concat_test_df.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only not working because I have the wrong dataset, it's too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
